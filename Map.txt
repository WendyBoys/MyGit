HashMap可以接受null键值和值，而Hashtable则不能；HashMap是非synchronized;

HashMap在底层数据结构上采用了数组＋链表＋红黑树，通过散列映射来存储键值对数据因为在查询上使用散列码（通过键生成一个数字作为数组下标，这个数字就是hash code）所以在查询上的访问速度比较快，HashMap最多允许一对键值对的Key为Null，允许多对键值对的value为Null。它是非线程安全的。在排序上面是无序的。

默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。


0.75 是空间和时间最优的 0.5（浪费空间 ） 浪费空间 1（大量冲突 导致链表长 查询时间增长）浪费时间
初始大小为2的指数幂 如果不是 比如13 会自动转换为16 扩容采取位运算而非取模运算 （效率） 位运算为了防止数组越界位运算必须是2的指数幂


具体的put过程

1.对key’值进行求hash值，然后再计算下标。

2.如果没有碰撞，直接放入桶中（空桶），（碰撞的意思就是计算出来的hash值相同，需要放在同一个桶中）。

3.如果碰撞了，用equals方法比较key值内容是否相同，相同就替代值，不同就链接到链表后面。

4.如果链表长度超过阀值8，就把链表转成红黑树，链表长度低于6，就不红黑树 ,转换为链表。

5.如果所有的桶满了（容量16*加载因子0.75），就需要resize（扩容2倍后重排）

链表转红黑树链表长=8
当数组长度<64时，优先扩容，当大于等于64时才转红黑树
链表转红黑树，阈值=8，实际此时链表长度是9



之所以选择红黑树，是因为二叉树在特定情况下，会形成一条线的结构，这跟链表查询的一样了，造成查询很深的问题，遍历查询会变的非常的慢，红黑树就是为了查询速度快，解决链表查询深度的问题，我们知道红黑树是属于平衡二叉树，但是为了保持平衡是需要付出代价的，但是该代价所损耗的资源要比遍历线性链表要少，所以当长度大于8的时候，会使用红黑树，如果链表的长度很短 的话，使用红黑树，反而会更慢


当重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了

HashMap在put的时候，插入的元素超过了容量（由负载因子决定）的范围就会触发扩容操作，就是rehash，这个会重新将原数组的内容重新hash到新的扩容数组中，在多线程的环境下，存在同时其他的元素也在进行put操作，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的


解决Hash冲突
 Hashmap里面的bucket出现了单链表的形式，散列表要解决的一个问题就是散列值的冲突问题，通常是两种方法：链表法和开放地址法。链表法就是将相同hash值的对象组织成一个链表放在hash值对应的槽位；开放地址法是通过一个探测算法，当某个槽位已经被占据的情况下继续查找下一个可以使用的槽位。

java.util.HashMap采用的链表法的方式，链表是单向链表。

系统总是将新添加的 Entry 对象放入 table 数组的 bucketIndex 索引处――如果 bucketIndex 索引处已经有了一个 Entry 对象，那新添加的 Entry 对象指向原有的 Entry 对象（产生一个 Entry 链），如果 bucketIndex 索引处没有 Entry 对象，也就是上面程序代码的 e 变量是 null，也就是新放入的 Entry 对象指向 null，也就是没有产生 Entry 链。

       HashMap里面没有出现hash冲突时，没有形成单链表时，hashmap查找元素很快,get()方法能够直接定位到元素，但是出现单链表后，单个bucket 里存储的不是一个 Entry，而是一个 Entry 链，系统只能必须按顺序遍历每个 Entry，直到找到想搜索的 Entry 为止――如果恰好要搜索的 Entry 位于该 Entry 链的最末端（该 Entry 是最早放入该 bucket 中），那系统必须循环到最后才能找到该元素。

       当创建 HashMap 时，有一个默认的负载因子（load factor），其默认值为 0.75，这是时间和空间成本上一种折衷：增大负载因子可以减少 Hash 表（就是那个 Entry 数组）所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的的操作（HashMap 的 get() 与 put() 方法都要用到查询）；减小负载因子会提高数据查询的性能，但会增加 Hash 表所占用的内存空间。

如果两个键的hashcode相同，你如何获取值对象？”当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，HashMap在链表中存储的是键值对，找到bucket位置之后，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。

ConcurrentHashMap为什么高效？
　　Hashtable低效主要是因为所有访问Hashtable的线程都争夺一把锁。如果容器有很多把锁，每一把锁控制容器中的一部分数据，那么当多个线程访问容器里的不同部分的数据时，线程之前就
不会存在锁的竞争，这样就可以有效的提高并发的访问效率。
　　这也正是ConcurrentHashMap使用的分段锁技术。将ConcurrentHashMap容器的数据分段存储，每一段数据分配一个Segment（锁），当线程占用其中一个Segment时，其他线程可正常访问
其他段数据。




LinkedHashMap

 public LinkedHashMap(int initialCapacity, float loadFactor) {
        super(initialCapacity, loadFactor);
        accessOrder = false;
    }

LinkedHashMap调用父类构造方法初始化时，还顺便设置了变量accessOrder = false，看上面得源码可以知道，这是给了迭代器一个参数，false代表迭代时使用插入得顺序

在LinkedHashMap中可以保持两种顺序，分别是插入顺序和访问顺序，这个是可以在LinkedHashMap的初始化方法中进行指定的。
相对于访问顺序，按照插入顺序进行编排被使用到的场景更多一些，所以默认是按照插入顺序进行编排

1.LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构。该结构由数组和链表+红黑树 在此基础上LinkedHashMap 增加了一条双向链表，保持遍历顺序和插入顺序一致的问题。





TreeMap

TreeMap实现了SotredMap接口，它是有序的集合。而且是一个红黑树结构，每个key-value都作为一个红黑树的节点。如果在调用TreeMap的构造函数时没有指定比较器，则根据key执行自然排序。这点会在接下来的代码中做说明，如果指定了比较器则按照比较器来进行排序。


自然排序：TreeMap的所有key必须实现Comparable接口，所有的key都是同一个类的对象
定制排序：创建TreeMap对象传入了一个Comparator对象，该对象负责对TreeMap中所有的key进行排序，采用定制排序不要求Map的key实现Comparable接口



HashMap是基于数组和链表/红黑树实现的。
HashMap默认容量是16
-
 HashMap最大容量2的30次方
-
 HashMap扩容机制，扩容到原数组的两倍



ConcurrentHashMap 同HashMap


1.8之前是分段 1.8及以后是sychonizer关键字加cas

cas全称为Compare-and-Swap（比较并交换），有3个操作数，分别是内存位置V、旧的的预期值A、新值B，那么当且仅当V符合旧的预期值A时，处理器用新值B更新V的值为B。并且这些处理过程有指令集的支持，因此看似读-写-改操作只是一个原子操作，所以不存在线程安全问题

优点：CAS操作是抱着乐观态度进行的，它总是认为自己可以成功完成操作。当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。失败的线程不会被挂起，仅是被告知失败，并允许再次尝试，当然也允许失败的线程放弃操作。基于这样的原理，CAS操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理。



缺点：CAS存在ABA问题，比如一个人账户里有100块钱，他想取50但是银行出现错误，同时执行了两次减少50的操作，但他自己只发出了一次指令。当第一次执行的时候采用CAS机制取出50块钱，但他的妈妈从别的操作系统给他又转了50块，这样账户里的钱又是100块，那么采用CAS机制就会继续执行扣款操作，这样就是ABA问题，丢了50块钱。

解决方案：ABA问题可以对每个值添加一个版本号来判断。

版权声明：本文为CSDN博主「qq_37685457」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_37685457/article/details/89889254

Hashtable默认容量是11(Hashtable默认大小是11是因为除（近似）质数求余的分散效果好：)

Hashtable最大容量Integer.MAX_VALUE - 8

Hashtable扩容机制，扩容到原数组的两倍+1


LinkedHashMap
继承自HashMap扩容机制同HashMap



TreeMap由红黑树实现，容量方面没有限制
